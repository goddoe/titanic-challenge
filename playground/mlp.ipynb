{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_wrapper(X, is_training, decay, name=None):\n",
    "    \"\"\"\n",
    "    Reference : \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\", https://arxiv.org/abs/1502.03167\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name or \"batch_nomalization\"):\n",
    "        gamma = tf.Variable(tf.ones([X.get_shape()[-1]]), \n",
    "                            trainable=True, \n",
    "                            name=\"gamma\")\n",
    "        beta = tf.Variable(tf.zeros([X.get_shape()[-1]]), \n",
    "                           trainable=True, \n",
    "                           name=\"beta\")\n",
    "        \n",
    "        global_mean = tf.Variable(tf.zeros([X.get_shape()[-1]]), \n",
    "                                  trainable=False, \n",
    "                                  name=\"global_mean\")\n",
    "        global_var = tf.Variable(tf.ones([X.get_shape()[-1]]), \n",
    "                                 trainable=False,\n",
    "                                 name=\"global_var\")\n",
    "\n",
    "        def calc_moments_in_train():\n",
    "            batch_mean, batch_var = tf.nn.moments(X,[0])\n",
    "            global_mean_update = tf.assign(global_mean,\n",
    "                                   global_mean * decay + batch_mean * (1 - decay))\n",
    "            global_var_update = tf.assign(global_var,\n",
    "                                  global_var * decay + batch_var * (1 - decay))\n",
    "            with tf.control_dependencies([global_mean_update, global_var_update]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        def calc_moments_in_predict():\n",
    "            return global_mean, global_var\n",
    "\n",
    "        mean, var = tf.cond(is_training, \n",
    "                            calc_moments_in_train,\n",
    "                            calc_moments_in_predict\n",
    "                           )\n",
    "    \n",
    "    return tf.nn.batch_normalization(X, mean, var, beta, gamma, 1e-3)\n",
    "\n",
    "\n",
    "\n",
    "def flatten(x, name=None):\n",
    "    with tf.variable_scope('flatten'):\n",
    "        dims = x.get_shape().as_list()\n",
    "        if len(dims) == 4:\n",
    "            flattened = tf.reshape(\n",
    "                x,\n",
    "                shape=[-1, dims[1] * dims[2] * dims[3]])\n",
    "        elif len(dims) == 2 or len(dims) == 1:\n",
    "            flattened = x\n",
    "        else:\n",
    "            raise ValueError('Expected n dimensions of 1, 2 or 4.  Found:',\n",
    "                             len(dims))\n",
    "\n",
    "        return flattened\n",
    "\n",
    "def linear(x, n_output, is_batch_norm=False, is_training=False, name=None, activation=None):\n",
    "    if len(x.get_shape()) != 2:\n",
    "        x = flatten(x)\n",
    "\n",
    "    n_input = x.get_shape().as_list()[1]\n",
    "    with tf.variable_scope(name or \"fc\"):\n",
    "        W = tf.get_variable(\n",
    "            name='W',\n",
    "            shape=[n_input, n_output],\n",
    "            dtype=tf.float32,\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        b = tf.get_variable(\n",
    "            name='b',\n",
    "            shape=[n_output],\n",
    "            dtype=tf.float32,\n",
    "            initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        h = tf.nn.bias_add(\n",
    "            name='h',\n",
    "            value=tf.matmul(x, W),\n",
    "            bias=b)\n",
    "        \n",
    "        if is_batch_norm:\n",
    "            h = batch_norm_wrapper(h, is_training, decay = 0.9)\n",
    "        \n",
    "        if activation:\n",
    "            h = activation(h)\n",
    "\n",
    "        return h, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(object):\n",
    "    def __init__(self, sess, input_dim, output_dim):\n",
    "\n",
    "        self.sess = sess\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.min_loss = None\n",
    "        self.best_accuracy = None\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.build_model()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def load(self, sess, weights_path, meta_path):\n",
    "        self.saver.restore(sess, weights_path)\n",
    "\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            meta = pickle.load(f)\n",
    "\n",
    "        self.mean = meta['mean']\n",
    "        self.std = meta['std']\n",
    "        self.min_loss = meta['min_loss']\n",
    "        self.input_dim = meta['input_dim']\n",
    "        self.output_dim = meta['output_dim']\n",
    "\n",
    "    def save(self, sess, weights_path, meta_path, flag_export_graph=False, graph_path=None):\n",
    "        meta = {\n",
    "            \"mean\": self.mean,\n",
    "            \"std\": self.std,\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"min_loss\": self.min_loss,\n",
    "            \"best_accuracy\": self.best_accuracy\n",
    "        }\n",
    "\n",
    "        with open(meta_path, \"wb\") as f:\n",
    "            pickle.dump(meta, f)\n",
    "\n",
    "        self.saver.save(sess, weights_path, latest_filename=\"recent.ckpt\", write_meta_graph=flag_export_graph)\n",
    "        \n",
    "    def build_model(self):\n",
    "        with tf.variable_scope('variable'):\n",
    "            X = tf.placeholder(dtype=tf.float32, \n",
    "                               shape=[None, self.input_dim],\n",
    "                               name=\"X\")\n",
    "            Y = tf.placeholder(dtype=tf.float32,\n",
    "                               shape=[None,2],\n",
    "                               name=\"Y\")\n",
    "            \n",
    "            learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "            is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "        \n",
    "        \n",
    "        \n",
    "        with tf.variable_scope('mlp_model'):\n",
    "            # declaration of model\n",
    "\n",
    "            h, _ = linear(X, 64, is_batch_norm=True, is_training=is_training, name=\"layer_1\", activation=tf.nn.relu)\n",
    "            h, _ = linear(h, 64, is_batch_norm=True, is_training=is_training, name=\"layer_2\", activation=tf.nn.relu)\n",
    "            Y_pred, _ = linear(h, self.output_dim, name=\"layer_3\")\n",
    "\n",
    "            # optimization\n",
    "            cost = tf.reduce_mean(tf.squared_difference(Y_pred, Y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "            init = tf.global_variables_initializer()\n",
    "        \n",
    "            correct_prediction = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Y_pred = Y_pred\n",
    "        self.accuracy = accuracy\n",
    "        self.learning_rate = learning_rate\n",
    "        self.is_training = is_training\n",
    "        self.cost = cost\n",
    "        self.optimizer = optimizer\n",
    "        self.init = init\n",
    "    \n",
    "    def train(self, X_train, Y_train, batch_size, n_epoch, learning_rate, save_dir_path, X_valid=None,\n",
    "              Y_valid=None, verbose_interval=100):\n",
    "\n",
    "        if self.min_loss is None:\n",
    "            self.min_loss = 999999999\n",
    "        \n",
    "        X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "        mean, std = tf.nn.moments(X_train_tensor, axes=0)\n",
    "        std = tf.sqrt(std)       \n",
    "        self.mean, self.std = self.sess.run([mean, std])\n",
    "\n",
    "        for epoch_i in range(n_epoch):\n",
    "            \n",
    "            rand_idx_list = np.random.permutation(range(len(X_train)))\n",
    "            n_batch = len(rand_idx_list) // batch_size\n",
    "            for batch_i in range(n_batch):\n",
    "                rand_idx = rand_idx_list[batch_i * batch_size: (batch_i + 1) * batch_size]\n",
    "                batch_x = X_train[rand_idx]\n",
    "                batch_y = Y_train[rand_idx]\n",
    "                self.sess.run(self.optimizer,\n",
    "                              feed_dict={self.X: (batch_x - self.mean) / self.std,\n",
    "                                         self.Y: batch_y,\n",
    "                                         self.learning_rate: learning_rate,\n",
    "                                         self.is_training:True})\n",
    "\n",
    "            loss, accuracy, Y, Y_pred = self.sess.run([self.cost, self.accuracy, self.Y, self.Y_pred ], feed_dict={self.X: (X_valid - self.mean) / self.std,\n",
    "                                                       self.Y: Y_valid,\n",
    "                                                        self.is_training:False})\n",
    "            if  epoch_i % verbose_interval == 0:\n",
    "                print(\"-\"*30)\n",
    "                print(\"epoh_i : {}\".format(epoch_i))\n",
    "                print(\"curr loss: {}, curr accuracy: {}, best_loss: {}, best_accuracy : {}\".format(loss, accuracy, self.min_loss, self.best_accuracy))\n",
    "\n",
    "            if loss < self.min_loss:\n",
    "                \n",
    "                self.min_loss = loss\n",
    "                self.best_accuracy = accuracy\n",
    "                \n",
    "                weights_path = \"{}/weights\".format(save_dir_path)\n",
    "                meta_path = \"{}/meta_data.pickle\".format(save_dir_path)\n",
    "                self.save(self.sess, weights_path=weights_path, meta_path=meta_path)\n",
    "                print(\"*\"*30)\n",
    "                print(\"curr loss: {}, curr accuracy: {}, best_loss: {}, best_accuracy : {}\".format(loss, accuracy, self.min_loss, self.best_accuracy))     \n",
    "                print(\"save current model\")\n",
    "\n",
    "        return self.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    train_df = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "    X_train_df = train_df.drop([\"Survived\",\"Sex\",\"Title\",\"Embarked\"], axis=1)\n",
    "    Y_train_df = train_df[\"Survived\"]\n",
    "    \n",
    "    \n",
    "    X_all= X_train_df.as_matrix()\n",
    "    Y_all = Y_train_df.as_matrix()\n",
    "    \n",
    "    # Y to one hot \n",
    "    n_class = 2\n",
    "    n_sample = len(Y_all)\n",
    "\n",
    "    tmp = np.zeros((n_sample, n_class))\n",
    "    tmp[np.arange(n_sample), Y_all] = 1\n",
    "    Y_all = tmp\n",
    "\n",
    "    # data\n",
    "    rand_idx = np.random.permutation(range(len(X_all)))\n",
    "    X_all = X_all[rand_idx]\n",
    "    Y_all = Y_all[rand_idx]\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    valid_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    data_num = len(X_all)\n",
    "    train_data_num = round(data_num * train_ratio)\n",
    "    valid_data_num = round(data_num * valid_ratio)\n",
    "    test_data_num = round(data_num * test_ratio)\n",
    "\n",
    "    X_train = X_all[:train_data_num]\n",
    "    Y_train = Y_all[:train_data_num]\n",
    "    X_valid = X_all[train_data_num:train_data_num + valid_data_num]\n",
    "    Y_valid = Y_all[train_data_num:train_data_num + valid_data_num]\n",
    "    X_test = X_all[train_data_num + valid_data_num:]\n",
    "    Y_test = Y_all[train_data_num + valid_data_num:]\n",
    "\n",
    "    input_dim = len(X_train[0])\n",
    "    output_dim = 2\n",
    "    print(input_dim)\n",
    "    \n",
    "#     mean = np.mean(X_train,axis=0)\n",
    "#     std = np.std(X_train,axis=0)\n",
    "#     X_train = (X_train - mean)/std\n",
    "\n",
    "    print(\"X_train shape : {}\\nY_train shape : {}\".format(np.shape(X_train), np.shape(Y_train)))\n",
    "    print(\"X_valid shape : {}\\nY_valid shape : {}\".format(np.shape(X_valid), np.shape(Y_valid)))\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "    mlp = MLP(sess, input_dim, output_dim)\n",
    "    # mlp.load(sess, './model/weights', './model/meta_data.pickle')\n",
    "    mlp.train(X_train, Y_train, X_valid=X_valid, Y_valid=Y_valid,\n",
    "                 batch_size=64, n_epoch=3000, learning_rate = 0.005, save_dir_path='./model', verbose_interval=300)\n",
    "\n",
    "\n",
    "    result_dict = {\n",
    "        'model' : mlp,\n",
    "        'mean' : mlp.mean,\n",
    "        'std' : mlp.std, \n",
    "        'X_all' :X_all,\n",
    "        'Y_all' :Y_all,\n",
    "        'X_train' : X_train,\n",
    "        'Y_train' : Y_train,\n",
    "        'X_valid' : X_valid,\n",
    "        'Y_valid' : Y_valid,\n",
    "        'X_test' : X_test,\n",
    "        'Y_test' : Y_test,\n",
    "    }\n",
    "    \n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "X_train shape : (713, 5)\n",
      "Y_train shape : (713, 2)\n",
      "X_valid shape : (89, 5)\n",
      "Y_valid shape : (89, 2)\n",
      "------------------------------\n",
      "epoh_i : 0\n",
      "curr loss: 0.30296915769577026, curr accuracy: 0.5842696629213483, best_loss: 999999999, best_accuracy : None\n",
      "******************************\n",
      "curr loss: 0.30296915769577026, curr accuracy: 0.5842696629213483, best_loss: 0.30296915769577026, best_accuracy : 0.5842696629213483\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.225380077958107, curr accuracy: 0.7303370786516854, best_loss: 0.225380077958107, best_accuracy : 0.7303370786516854\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.22436174750328064, curr accuracy: 0.6853932584269663, best_loss: 0.22436174750328064, best_accuracy : 0.6853932584269663\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.19847488403320312, curr accuracy: 0.7078651685393258, best_loss: 0.19847488403320312, best_accuracy : 0.7078651685393258\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.19472169876098633, curr accuracy: 0.6966292134831461, best_loss: 0.19472169876098633, best_accuracy : 0.6966292134831461\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.19405965507030487, curr accuracy: 0.7078651685393258, best_loss: 0.19405965507030487, best_accuracy : 0.7078651685393258\n",
      "save current model\n",
      "******************************\n",
      "curr loss: 0.19008351862430573, curr accuracy: 0.7640449438202247, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "save current model\n",
      "------------------------------\n",
      "epoh_i : 300\n",
      "curr loss: 0.2055908441543579, curr accuracy: 0.7752808988764045, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 600\n",
      "curr loss: 0.20899425446987152, curr accuracy: 0.7191011235955056, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 900\n",
      "curr loss: 0.2322811782360077, curr accuracy: 0.7078651685393258, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 1200\n",
      "curr loss: 0.2338113635778427, curr accuracy: 0.6741573033707865, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 1500\n",
      "curr loss: 0.23099066317081451, curr accuracy: 0.7078651685393258, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 1800\n",
      "curr loss: 0.22157728672027588, curr accuracy: 0.7078651685393258, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 2100\n",
      "curr loss: 0.22839683294296265, curr accuracy: 0.6966292134831461, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 2400\n",
      "curr loss: 0.22535382211208344, curr accuracy: 0.7191011235955056, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n",
      "------------------------------\n",
      "epoh_i : 2700\n",
      "curr loss: 0.23345491290092468, curr accuracy: 0.7078651685393258, best_loss: 0.19008351862430573, best_accuracy : 0.7640449438202247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'X_all': array([[2, 0, 3, 0, 0],\n",
       "        [3, 0, 3, 0, 0],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        ..., \n",
       "        [2, 1, 1, 1, 2],\n",
       "        [1, 2, 3, 1, 2],\n",
       "        [2, 1, 1, 1, 2]]), 'X_test': array([[3, 1, 2, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [2, 2, 3, 0, 4],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [1, 3, 3, 1, 3],\n",
       "        [3, 1, 1, 0, 3],\n",
       "        [2, 2, 1, 1, 4],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 1, 2, 1, 3],\n",
       "        [3, 0, 2, 0, 0],\n",
       "        [2, 0, 3, 0, 0],\n",
       "        [2, 0, 2, 0, 0],\n",
       "        [1, 2, 3, 0, 2],\n",
       "        [1, 2, 3, 1, 2],\n",
       "        [2, 0, 2, 0, 0],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [1, 3, 3, 0, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 0, 1, 1, 0],\n",
       "        [1, 3, 3, 0, 3],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [1, 1, 3, 0, 1],\n",
       "        [3, 1, 2, 0, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [2, 2, 2, 0, 4],\n",
       "        [3, 0, 1, 0, 0],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [1, 2, 3, 1, 2],\n",
       "        [1, 2, 3, 0, 2],\n",
       "        [1, 2, 2, 1, 2],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 0, 3],\n",
       "        [3, 0, 1, 0, 0],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [1, 2, 3, 0, 2],\n",
       "        [3, 2, 1, 1, 6],\n",
       "        [1, 2, 3, 0, 2],\n",
       "        [1, 1, 2, 1, 1],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [2, 1, 0, 1, 2],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 2, 1, 1, 6],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [2, 1, 2, 0, 2],\n",
       "        [3, 1, 2, 0, 3],\n",
       "        [3, 0, 2, 0, 0],\n",
       "        [3, 0, 2, 0, 0],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 0, 2, 0, 0],\n",
       "        [3, 2, 2, 0, 6],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [3, 2, 2, 1, 6],\n",
       "        [2, 1, 2, 0, 2],\n",
       "        [1, 1, 3, 1, 1],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 3, 1, 3],\n",
       "        [3, 1, 2, 0, 3],\n",
       "        [1, 1, 3, 1, 1],\n",
       "        [2, 1, 0, 1, 2],\n",
       "        [3, 2, 0, 1, 6],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 0, 3],\n",
       "        [2, 1, 2, 1, 2],\n",
       "        [1, 1, 3, 1, 1],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [1, 3, 2, 1, 3],\n",
       "        [1, 2, 3, 0, 2],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 1, 1, 1, 3],\n",
       "        [3, 0, 1, 0, 0],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [1, 2, 3, 1, 2],\n",
       "        [2, 1, 1, 1, 2]]), 'X_train': array([[2, 0, 3, 0, 0],\n",
       "        [3, 0, 3, 0, 0],\n",
       "        [3, 1, 0, 1, 3],\n",
       "        ..., \n",
       "        [1, 2, 0, 1, 2],\n",
       "        [2, 3, 1, 1, 6],\n",
       "        [2, 1, 1, 0, 2]]), 'X_valid': array([[ 3,  1,  2,  0,  3],\n",
       "        [ 1,  1,  3,  1,  1],\n",
       "        [ 1,  3,  3,  0,  3],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 1,  2,  2,  1,  2],\n",
       "        [ 2,  2,  2,  0,  4],\n",
       "        [ 3,  1,  0,  0,  3],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 1,  1,  3,  0,  1],\n",
       "        [ 3,  2,  2,  0,  6],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 2,  2,  1,  1,  4],\n",
       "        [ 1,  2,  3,  0,  2],\n",
       "        [ 2,  2,  2,  1,  4],\n",
       "        [ 3,  1,  0,  0,  3],\n",
       "        [ 2,  0,  3,  0,  0],\n",
       "        [ 1,  0,  3,  1,  0],\n",
       "        [ 3,  1,  2,  0,  3],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 2,  1,  2,  0,  2],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 1,  1,  3,  0,  1],\n",
       "        [ 1,  2,  3,  1,  2],\n",
       "        [ 3,  0,  3,  0,  0],\n",
       "        [ 3,  2,  0,  1,  6],\n",
       "        [ 2,  1,  1,  1,  2],\n",
       "        [ 3,  0,  0,  1,  0],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  2,  0,  1,  6],\n",
       "        [ 3,  1,  2,  0,  3],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  1,  1,  0,  3],\n",
       "        [ 2,  1,  3,  0,  2],\n",
       "        [ 3,  1,  3,  1,  3],\n",
       "        [ 2,  2,  1,  1,  4],\n",
       "        [ 1,  2,  3,  1,  2],\n",
       "        [ 1,  0,  3,  0,  0],\n",
       "        [ 2,  1,  2,  0,  2],\n",
       "        [ 2,  1,  1,  1,  2],\n",
       "        [ 3,  2,  2,  0,  6],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 1, 71,  3,  1, 71],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  1,  3,  1,  3],\n",
       "        [ 1,  0,  3,  0,  0],\n",
       "        [ 3,  0,  1,  0,  0],\n",
       "        [ 3,  2,  3,  0,  6],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  0,  3,  0,  0],\n",
       "        [ 2,  3,  1,  1,  6],\n",
       "        [ 1,  2,  3,  0,  2],\n",
       "        [ 1,  1,  3,  0,  1],\n",
       "        [ 3,  0,  3,  0,  0],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 1,  1,  3,  1,  1],\n",
       "        [ 3,  2,  0,  1,  6],\n",
       "        [ 2,  0,  2,  1,  0],\n",
       "        [ 3,  0,  2,  0,  0],\n",
       "        [ 1,  1,  3,  1,  1],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 2,  3,  1,  1,  6],\n",
       "        [ 3,  1,  1,  0,  3],\n",
       "        [ 3,  0,  2,  0,  0],\n",
       "        [ 2,  2,  1,  1,  4],\n",
       "        [ 3,  1,  0,  0,  3],\n",
       "        [ 1,  2,  2,  1,  2],\n",
       "        [ 3,  1,  1,  0,  3],\n",
       "        [ 1,  1,  2,  1,  1],\n",
       "        [ 1,  2,  0,  1,  2],\n",
       "        [ 2,  1,  1,  1,  2],\n",
       "        [ 3,  1,  0,  0,  3],\n",
       "        [ 1,  2,  2,  1,  2],\n",
       "        [ 3,  2,  0,  1,  6],\n",
       "        [ 2,  2,  1,  1,  4],\n",
       "        [ 2,  1,  3,  0,  2],\n",
       "        [ 3,  0,  2,  0,  0],\n",
       "        [ 3,  1,  2,  0,  3],\n",
       "        [ 1,  2,  3,  0,  2],\n",
       "        [ 3,  2,  2,  0,  6],\n",
       "        [ 3,  0,  1,  0,  0],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  1,  1,  1,  3],\n",
       "        [ 3,  1,  0,  1,  3],\n",
       "        [ 2,  1,  2,  0,  2],\n",
       "        [ 1,  2,  0,  1,  2],\n",
       "        [ 1,  1,  3,  1,  1],\n",
       "        [ 1,  1,  3,  0,  1],\n",
       "        [ 1,  3,  3,  1,  3],\n",
       "        [ 3,  3,  0,  1,  9]]), 'Y_all': array([[ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.]]), 'Y_test': array([[ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.]]), 'Y_train': array([[ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]), 'Y_valid': array([[ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]), 'mean': array([ 2.30575037,  2.27068734,  1.50911641,  0.60028052,  4.47124815], dtype=float32), 'model': <__main__.MLP at 0x11c57bb38>, 'std': array([  0.83519036,   8.08481789,   1.11485493,   0.48984   ,  16.16266251], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
